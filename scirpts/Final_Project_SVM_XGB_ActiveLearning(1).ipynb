{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zMZWdUt2y3q1",
    "outputId": "06d73155-4833-42c8-f1b9-a585231188b8"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/igemiracle/02620_final_project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQLQ7DVFzGVb",
    "outputId": "3a292d74-d582-491e-d679-b9184ae626d9"
   },
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "495d433e-3d73-4641-a7eb-ec715f4610ae"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghs2iRV9XNim"
   },
   "source": [
    "We first try to use gridsearch to find the best parameters for SVM models, and use the best setting to predict test data and evaluate the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OjEJ741T5dFR",
    "outputId": "7152bd45-fd06-4fd4-b19e-ace5ca22f2ad"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of datasets for processing\n",
    "datasets = ['baron', 'cellBench', 'zheng']\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['auto', 'scale'],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} dataset\")\n",
    "\n",
    "    # Store the best model, its validation accuracy, and F1-score for each fold\n",
    "    best_model = None\n",
    "    highest_valid_acc = 0\n",
    "    best_f1_score = 0\n",
    "\n",
    "    for fold in range(1, 11):\n",
    "        # Load training and validation data\n",
    "        train_features = pd.read_csv(f\"clean_data_pca/{dataset}/fold_{fold}/train_features.csv\")\n",
    "        train_labels = pd.read_csv(f\"clean_data_pca/{dataset}/fold_{fold}/train_labels.csv\")\n",
    "\n",
    "        # Grid search with cross-validation\n",
    "        grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(train_features, train_labels.values.ravel())\n",
    "\n",
    "        # Calculate F1-score for the best model\n",
    "        f1 = f1_score(train_labels.values.ravel(), grid_search.predict(train_features), average='macro')\n",
    "\n",
    "        # Check if there is a higher validation accuracy or F1-score\n",
    "        if grid_search.best_score_ > highest_valid_acc:\n",
    "            highest_valid_acc = grid_search.best_score_\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_f1_score = f1\n",
    "\n",
    "        print(f\"Fold {fold}: Best params = {grid_search.best_params_}, Best validation accuracy = {grid_search.best_score_}, F1-Score = {f1}\")\n",
    "\n",
    "    print(f\"Best model parameters for {dataset} dataset: {best_model.get_params()}\")\n",
    "    print(f\"Highest validation accuracy: {highest_valid_acc}, Best F1-score: {best_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of datasets for processing\n",
    "datasets = ['baron', 'cellBench', 'zheng']\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['auto', 'scale'],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Initialize lists to store the average errors for plotting\n",
    "average_train_errors = []\n",
    "average_test_errors = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} dataset\")\n",
    "\n",
    "    # Store the cumulative error for each fold to calculate the average later\n",
    "    cumulative_train_error = 0\n",
    "    cumulative_test_error = 0\n",
    "\n",
    "    for fold in range(1, 11):\n",
    "        # Load training and validation data\n",
    "        train_features = pd.read_csv(f\"clean_data_pca/{dataset}/fold_{fold}/train_features.csv\")\n",
    "        train_labels = pd.read_csv(f\"clean_data_pca/{dataset}/fold_{fold}/train_labels.csv\").values.ravel()\n",
    "\n",
    "        # Grid search with cross-validation\n",
    "        grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(train_features, train_labels)\n",
    "\n",
    "        # Calculate and accumulate train error for the fold\n",
    "        train_error = 1 - grid_search.best_score_\n",
    "        cumulative_train_error += train_error\n",
    "\n",
    "        # Validate the best model on the test set and calculate the error\n",
    "        best_model = grid_search.best_estimator_\n",
    "        test_error = 1 - accuracy_score(train_labels, best_model.predict(train_features))\n",
    "        cumulative_test_error += test_error\n",
    "\n",
    "    # Calculate the average error across all folds\n",
    "    average_train_error = cumulative_train_error / 10\n",
    "    average_test_error = cumulative_test_error / 10\n",
    "\n",
    "    # Append the average errors for the current dataset to the list\n",
    "    average_train_errors.append(average_train_error)\n",
    "    average_test_errors.append(average_test_error)\n",
    "\n",
    "    # Print the average errors for the current dataset\n",
    "    print(f\"{dataset} - Average training error: {average_train_error}\")\n",
    "    print(f\"{dataset} - Average test error: {average_test_error}\")\n",
    "\n",
    "# Plotting the average training and test errors for each dataset\n",
    "x = np.arange(len(datasets))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x - width/2, average_train_errors, width, label='Training Error')\n",
    "ax.bar(x + width/2, average_test_errors, width, label='Test Error')\n",
    "\n",
    "ax.set_xlabel('Datasets')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Average Training and Test Errors for SVM')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(datasets)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Training and test errors for SVM and XGBoost\n",
    "svm_train_errors = [0.08979592802470161, 0.0, 0.09768055555555553]\n",
    "svm_test_errors = [0.07345808879184441, 0.0, 0.07024999999999999]\n",
    "xgb_train_errors = [0.0311086797957695, 0.0, 0.062671875]\n",
    "xgb_test_errors = [0.07221006564551424, 0.0029583657419410825, 0.1434375]\n",
    "\n",
    "# Dataset names\n",
    "datasets = ['Baron', 'CellBench', 'Zheng']\n",
    "\n",
    "# Set up for the bar widths and positions\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(datasets))\n",
    "\n",
    "# Warm color palette\n",
    "colors = ['#e76f51', '#f4a261', '#e9c46a', '#2a9d8f']  # Adjust the colors to match the image\n",
    "\n",
    "# Creating the bar plots\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.bar(index, svm_train_errors, bar_width, label='SVM Train Error', color=colors[0])\n",
    "plt.bar(index + bar_width, svm_test_errors, bar_width, label='SVM Test Error', color=colors[1])\n",
    "\n",
    "plt.bar(index + bar_width * 2, xgb_train_errors, bar_width, label='XGBoost Train Error', color=colors[2])\n",
    "plt.bar(index + bar_width * 3, xgb_test_errors, bar_width, label='XGBoost Test Error', color=colors[3])\n",
    "\n",
    "# Adding labels and titles\n",
    "plt.xlabel('Datasets')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Training and Test Errors for SVM and XGBoost')\n",
    "plt.xticks(index + bar_width * 1.5, datasets)\n",
    "plt.legend()\n",
    "\n",
    "# Output the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qVuJVsNSvle"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "datasets_info = [\n",
    "    {\"features\": \"imm_adata_fselected_107.csv\", \"labels\": \"imm_Labels.csv\"},\n",
    "    {\"features\": \"lc_adata_fselected_31.csv\", \"labels\": \"lc_Labels.csv\"},\n",
    "    {\"features\": \"pan_adata_fselected_8.csv\", \"labels\": \"pan_Labels.csv\"}\n",
    "]\n",
    "\n",
    "for dataset in datasets_info:\n",
    "    print(f\"Processing dataset with features {dataset['features']}\")\n",
    "\n",
    "    # Load features and labels\n",
    "    features = pd.read_csv(f\"{dataset['features']}\")\n",
    "    labels = pd.read_csv(f\"{dataset['labels']}\")\n",
    "\n",
    "    # Use LabelEncoder to convert categorical labels into integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels.iloc[:, 0])\n",
    "\n",
    "    # Create an instance of XGBoost classifier\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=len(label_encoder.classes_),\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and F1-score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Results for {dataset['features'].split('_')[0]} dataset:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1-score: {f1}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "datasets_info = [\n",
    "    {\"features\": \"imm_adata_fselected_107.csv\", \"labels\": \"imm_Labels.csv\"},\n",
    "    {\"features\": \"lc_adata_fselected_31.csv\", \"labels\": \"lc_Labels.csv\"},\n",
    "    {\"features\": \"pan_adata_fselected_8.csv\", \"labels\": \"pan_Labels.csv\"}\n",
    "]\n",
    "\n",
    "for dataset in datasets_info:\n",
    "    print(f\"Processing dataset with features {dataset['features']}\")\n",
    "\n",
    "    # Load features and labels\n",
    "    features = pd.read_csv(f\"{dataset['features']}\")\n",
    "    labels = pd.read_csv(f\"{dataset['labels']}\")\n",
    "\n",
    "    # Use LabelEncoder to convert categorical labels into integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels.iloc[:, 0])\n",
    "\n",
    "    # Create an instance of SVM classifier\n",
    "    model = SVC(\n",
    "        C=1.0,  # Regularization parameter\n",
    "        kernel='rbf',  # Specifies the kernel type to be used in the algorithm\n",
    "        gamma='scale',  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "        probability=True,  # Whether to enable probability estimates (needed for F1-score)\n",
    "        random_state=42  # Random seed for reproducibility\n",
    "    )\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and F1-score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Results for {dataset['features'].split('_')[0]} dataset:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1-score: {f1}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data for the heatmap\n",
    "data = {\n",
    "    'baron': [0.495124148777054, 0.5017161996733301, 0.6109106426919281],\n",
    "    'cellBench': [0.6346396368152479, 0.9972228257593857, 0.9960945557360741],\n",
    "    'Zheng': [0.3181956174307169, 0.9204406786649237, 0.8555613418858459]\n",
    "}\n",
    "df = pd.DataFrame(data, index=['K-Means', 'SVM', 'XGBoost'])\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(df, annot=True, fmt=\".3f\", cmap='Oranges')\n",
    "\n",
    "# Set the labels\n",
    "plt.title('F1-Score Heatmap')\n",
    "plt.xlabel('Datasets')\n",
    "plt.ylabel('Methods')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmnowuYQXkU7"
   },
   "source": [
    "But actually, if we just use gridsearch and crossvalidation on train_data, that should be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKyawvpWKeVE",
    "outputId": "c4eed537-2aa1-4292-c111-b59c7b231eaf"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of datasets for processing\n",
    "datasets = ['baron', 'cellBench', 'zheng']\n",
    "\n",
    "# Define the parameter grid for the SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['auto', 'scale'],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Process each dataset\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} dataset\")\n",
    "\n",
    "    # Load training data\n",
    "    train_features = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_features.csv\")\n",
    "    train_labels = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_labels.csv\")\n",
    "\n",
    "    # Create an instance of SVC and GridSearchCV for parameter optimization\n",
    "    svc = SVC()\n",
    "    grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(train_features, train_labels.values.ravel())\n",
    "\n",
    "    # Output the best model's parameters and cross-validation accuracy\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    print(f\"{dataset}: Best model parameters: {best_params}\")\n",
    "    print(f\"{dataset}: Best cross-validation accuracy: {best_score}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jqcMiXUX3mK"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XA7H9o59Oefz",
    "outputId": "17eedcca-8ea0-4fe8-bcc4-3508fab1a61b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of datasets for processing\n",
    "datasets = ['baron', 'cellBench', 'zheng']\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} dataset\")\n",
    "\n",
    "    # Load training data\n",
    "    train_features = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_features.csv\")\n",
    "    train_labels = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_labels.csv\")\n",
    "\n",
    "    # Use LabelEncoder to convert categorical labels into integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(train_labels.iloc[:, 0])  # Assuming labels are in the first column\n",
    "\n",
    "    # Create an instance of XGBoost classifier\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',  # Using softmax for multi-class classification\n",
    "        num_class=len(label_encoder.classes_),  # Number of classes\n",
    "        n_estimators=100,  # Number of trees\n",
    "        learning_rate=0.05,  # Learning rate\n",
    "        max_depth=5,  # Maximum depth of the trees\n",
    "        random_state=42  # Random seed for reproducibility\n",
    "    )\n",
    "\n",
    "    # Use 5-fold cross-validation to evaluate the model\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, train_features, train_labels_encoded, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    # Output the results of cross-validation\n",
    "    print(f\"{dataset}: Cross-validation scores: {scores}\")\n",
    "    print(f\"{dataset}: Mean accuracy: {np.mean(scores)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of datasets for processing\n",
    "datasets = ['baron', 'cellBench', 'zheng']\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} dataset\")\n",
    "\n",
    "    # Load training data\n",
    "    train_features = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_features.csv\")\n",
    "    train_labels = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_labels.csv\")\n",
    "\n",
    "    # Use LabelEncoder to convert categorical labels into integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(train_labels.iloc[:, 0])  # Assuming labels are in the first column\n",
    "\n",
    "    # Create an instance of XGBoost classifier\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',  # Using softmax for multi-class classification\n",
    "        num_class=len(label_encoder.classes_),  # Number of classes\n",
    "        n_estimators=100,  # Number of trees\n",
    "        learning_rate=0.05,  # Learning rate\n",
    "        max_depth=5,  # Maximum depth of the trees\n",
    "        random_state=42  # Random seed for reproducibility\n",
    "    )\n",
    "\n",
    "    # Use 5-fold cross-validation to evaluate the model\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # cross_validate allows to retrieve both train and test scores\n",
    "    scores = cross_validate(model, train_features, train_labels_encoded, cv=kfold, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "    # Calculate training and testing errors\n",
    "    train_error = np.mean(1 - scores['train_score'])\n",
    "    test_error = np.mean(1 - scores['test_score'])\n",
    "\n",
    "    # Output the results of cross-validation\n",
    "    print(f\"{dataset}: Training error: {train_error}\")\n",
    "    print(f\"{dataset}: Test error: {test_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Given train and test errors for each dataset\n",
    "train_errors = [0.0311086797957695, 0.0, 0.062671875]\n",
    "test_errors = [0.07221006564551424, 0.0029583657419410825, 0.1434375]\n",
    "datasets = ['baron', 'cellBench', 'zheng']\n",
    "\n",
    "# Set up the bar width and positions\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(datasets))\n",
    "\n",
    "# Create the bars for train and test errors\n",
    "plt.bar(index, train_errors, bar_width, label='Train Error', color='blue')\n",
    "plt.bar(index + bar_width, test_errors, bar_width, label='Test Error', color='orange')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Datasets')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Training and Test Errors for XGBoost across Datasets')\n",
    "plt.xticks(index + bar_width / 2, datasets)\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of datasets for processing\n",
    "datasets = ['baron', 'cellBench', 'zheng']\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} dataset\")\n",
    "\n",
    "    # Load training data\n",
    "    train_features = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_features.csv\")\n",
    "    train_labels = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_labels.csv\")\n",
    "\n",
    "    # Use LabelEncoder to convert categorical labels into integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(train_labels.iloc[:, 0])  # Assuming labels are in the first column\n",
    "\n",
    "    # Create an instance of XGBoost classifier\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',  # Using softmax for multi-class classification\n",
    "        num_class=len(label_encoder.classes_),  # Number of classes\n",
    "        n_estimators=100,  # Number of trees\n",
    "        learning_rate=0.05,  # Learning rate\n",
    "        max_depth=5,  # Maximum depth of the trees\n",
    "        random_state=42  # Random seed for reproducibility\n",
    "    )\n",
    "\n",
    "    # Define a custom scorer for F1-score that calculates the macro average F1-score\n",
    "    f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "    # Use 5-fold cross-validation to evaluate the model using both accuracy and F1-score\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accuracy_scores = cross_val_score(model, train_features, train_labels_encoded, cv=kfold, scoring='accuracy')\n",
    "    f1_scores = cross_val_score(model, train_features, train_labels_encoded, cv=kfold, scoring=f1_scorer)\n",
    "\n",
    "    # Output the results of cross-validation\n",
    "    print(f\"{dataset}: Cross-validation accuracy scores: {accuracy_scores}\")\n",
    "    print(f\"{dataset}: Mean accuracy: {np.mean(accuracy_scores)}\")\n",
    "    print(f\"{dataset}: Cross-validation F1-scores: {f1_scores}\")\n",
    "    print(f\"{dataset}: Mean F1-score: {np.mean(f1_scores)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeMETpQyX83m"
   },
   "source": [
    "# Active Learning: Random Sampling v.s. Uncertainty Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuhd_GVXYHTX"
   },
   "source": [
    "We use AL on the first dataset to see if AL works. We start from 20% of data and end at 33% of data. Since the data has a very big volume, random batch sampling would be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgoCxxbgRaE_",
    "outputId": "5fc43ed7-c043-4668-c4d5-54407e5fab41"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "\n",
    "dataset = 'baron'\n",
    "\n",
    "# Load feature and label data\n",
    "X = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_features.csv\")\n",
    "y = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_labels.csv\")\n",
    "\n",
    "# Convert categorical labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y.iloc[:, 0])  # This will encode the original classes to integers\n",
    "y_encoded = pd.DataFrame(y_encoded, columns=['label'])  # Create a DataFrame from the encoded labels\n",
    "df = pd.concat([X, y_encoded], axis=1)\n",
    "\n",
    "unique_y_classes = np.unique(y)\n",
    "label_encoder_classes = label_encoder.classes_\n",
    "\n",
    "# Check if all unique classes in 'y' are present in the LabelEncoder's classes\n",
    "if set(unique_y_classes) - set(label_encoder_classes):\n",
    "    print(f\"Classes in 'y' that are not present in LabelEncoder classes: {set(unique_y_classes) - set(label_encoder_classes)}\")\n",
    "\n",
    "# Check if there are any classes in LabelEncoder that are not in 'y'\n",
    "if set(label_encoder_classes) - set(unique_y_classes):\n",
    "    print(f\"Classes in LabelEncoder that are not present in 'y': {set(label_encoder_classes) - set(unique_y_classes)}\")\n",
    "\n",
    "# Set random seed\n",
    "seed_num = [40, 41, 42]\n",
    "\n",
    "# Create list to store the results\n",
    "result_train_random_batch = []\n",
    "result_rest_random_batch = []\n",
    "\n",
    "# Loop over 5 times\n",
    "for seed in range(len(seed_num)):\n",
    "    result_train_random_batch.append([])\n",
    "    result_rest_random_batch.append([])\n",
    "\n",
    "    np.random.seed(seed_num[seed])\n",
    "    sdf = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    origin_len = sdf['label'].size // 5  # From 20% of data\n",
    "    half_len = sdf['label'].size // 3  # To 30% of data\n",
    "    iter_num = (half_len - origin_len) // 3\n",
    "\n",
    "    dff = sdf.iloc[0:origin_len]\n",
    "    rest_dataset = sdf.iloc[origin_len:]\n",
    "\n",
    "    score = []\n",
    "    score_rest = []\n",
    "    for i in range(iter_num):\n",
    "        # Model prediction\n",
    "        X = dff[dff.columns[0:-1]]\n",
    "        X_rest = rest_dataset[rest_dataset.columns[0:-1]]\n",
    "        y = dff[dff.columns[-1]]\n",
    "        y_rest = rest_dataset[rest_dataset.columns[-1]]\n",
    "\n",
    "        xgt = xgb.XGBClassifier(n_estimators=10, max_depth = 10)\n",
    "\n",
    "        # Cross-validate the model\n",
    "        y_pred = cross_val_predict(xgt, X, y, cv=3)\n",
    "        # Fit the model\n",
    "        xgt.fit(X, y)\n",
    "        y_rest_pred = xgt.predict(X_rest)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        acc = metrics.accuracy_score(y, y_pred)\n",
    "        rest_acc = metrics.accuracy_score(y_rest, y_rest_pred)\n",
    "\n",
    "        # Store results\n",
    "        score.append(acc)\n",
    "        score_rest.append(rest_acc)\n",
    "        result_train_random_batch[seed].append(acc)\n",
    "        result_rest_random_batch[seed].append(rest_acc)\n",
    "\n",
    "        # Choose the next data randomly\n",
    "        selected_indices = random.sample(range(len(rest_dataset)), 3)\n",
    "        # Add selected data to the training set\n",
    "        dff = pd.concat([dff, rest_dataset.iloc[selected_indices]], axis=0)\n",
    "        rest_dataset = rest_dataset.drop(rest_dataset.index[selected_indices])\n",
    "        rest_dataset = rest_dataset.reset_index(drop=True)\n",
    "\n",
    "        # Reset index\n",
    "        rest_dataset = rest_dataset.reset_index(drop=True)\n",
    "\n",
    "        datasize = origin_len + 3 * i\n",
    "        print(datasize, acc)\n",
    "\n",
    "    # Calculate and print overall online accuracy\n",
    "    online_acc = np.average(score)\n",
    "    print('-------------------------------------------------')\n",
    "    print(score, score_rest)\n",
    "    print(np.average(score), score_rest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uri2DHAnYWLp"
   },
   "source": [
    "For uncertainty samping, we also use a more efficient version, which is batch sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_L4_k4UKTwbn",
    "outputId": "4b8876a6-c7bc-4940-8122-19b0e018d242"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import random\n",
    "\n",
    "# Fetch dataset\n",
    "dataset = 'baron'\n",
    "X = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_features.csv\")\n",
    "y = pd.read_csv(f\"clean_data_kmeans/{dataset}/train_labels.csv\")\n",
    "\n",
    "# Convert categorical labels into integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y.iloc[:, 0])  # Assuming labels are in the first column\n",
    "y = pd.DataFrame(y, columns=['label'])\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Define seed numbers\n",
    "seed_num = [40, 41, 42]\n",
    "\n",
    "# Initialize lists to store results\n",
    "result_train_uncertain = []\n",
    "result_rest_uncertain = []\n",
    "\n",
    "# Loop through each seed to perform randomized trials\n",
    "for seed in range(len(seed_num)):\n",
    "    result_train_uncertain.append([])\n",
    "    result_rest_uncertain.append([])\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(seed_num[seed])\n",
    "    sdf = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Define initial training size (20% of data) and target size (50% of data)\n",
    "    origin_len = sdf['label'].size // 5\n",
    "    half_len = sdf['label'].size // 3\n",
    "    iter_num = (half_len - origin_len) // 3\n",
    "\n",
    "    # Split initial data into training and remaining datasets\n",
    "    dff = sdf.iloc[0:origin_len]\n",
    "    rest_dataset = sdf.iloc[origin_len:]\n",
    "\n",
    "    score = []\n",
    "    score_rest = []\n",
    "\n",
    "    # Iteratively train model and evaluate\n",
    "    for i in range(int(iter_num)):\n",
    "        # Separate features and labels\n",
    "        X = dff[dff.columns[0:-1]]\n",
    "        X_rest = rest_dataset[rest_dataset.columns[0:-1]]\n",
    "        y = dff[dff.columns[-1]]\n",
    "        y_rest = rest_dataset[rest_dataset.columns[-1]]\n",
    "\n",
    "        # Initialize and train XGBoost classifier\n",
    "        xgt = xgb.XGBClassifier(n_estimators=10, max_depth = 10)\n",
    "        y_pred = cross_val_predict(xgt, X, y, cv=5)\n",
    "        xgt.fit(X, y)\n",
    "        y_rest_pred = xgt.predict(X_rest)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        acc = metrics.accuracy_score(y, y_pred)\n",
    "        rest_acc = metrics.accuracy_score(y_rest, y_rest_pred)\n",
    "\n",
    "        # Store accuracy results\n",
    "        score.append(acc)\n",
    "        score_rest.append(rest_acc)\n",
    "        result_train_uncertain[seed].append(acc)\n",
    "        result_rest_uncertain[seed].append(rest_acc)\n",
    "\n",
    "        # Determine least certain predictions and select data for training\n",
    "        proba = xgt.predict_proba(rest_dataset[rest_dataset.columns[0:-1]])\n",
    "        uncertainty = 1 - proba.max(axis=1)  # Calculate uncertainty\n",
    "        max_positions_batch = np.argpartition(uncertainty, -3)[-3:]  # Get indices of top 3 uncertain samples\n",
    "        dff = pd.concat([dff, rest_dataset.iloc[max_positions_batch]], axis=0)\n",
    "\n",
    "        # Update the remaining dataset\n",
    "        rest_dataset = rest_dataset.drop(rest_dataset.index[max_positions_batch])\n",
    "        rest_dataset = rest_dataset.reset_index(drop=True)\n",
    "\n",
    "        # Print current training dataset size and accuracy\n",
    "        datasize = origin_len + 3 * i\n",
    "        print(datasize, acc)\n",
    "\n",
    "    # Calculate and print overall accuracy for online training\n",
    "    online_acc = np.average(score)\n",
    "    print('-------------------------------------------------')\n",
    "    print('Training scores:', score)\n",
    "    print('Test scores:', score_rest)\n",
    "    print('Mean training accuracy:', np.average(score), 'Mean test accuracy:', score_rest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rs9K0GD1Yi0t"
   },
   "source": [
    "Finally, we could compare the methods, and find that we could use less data to have the same level of accuracy or we could have a better performance model under same amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "ZEz7AZfFVv2Y",
    "outputId": "11f13c16-2575-4bd5-b35f-09affe01d273"
   },
   "outputs": [],
   "source": [
    "avg_rest_uncertain = np.mean(result_rest_uncertain, axis=0)\n",
    "std_rest_uncertain = np.std(result_rest_uncertain, axis=0)\n",
    "\n",
    "avg_rest_random = np.mean(result_rest_random_batch, axis=0)\n",
    "std_rest_random = np.std(result_rest_random_batch, axis=0)\n",
    "\n",
    "# Assuming 'result_rest_uncertain' is a list of lists where each sub-list represents an experiment\n",
    "# and contains accuracies for different train data sizes\n",
    "x1 = np.arange(1371, len(avg_rest_uncertain) * 3 + 1371, 3)  # Adjusted to match the length of the average lists\n",
    "\n",
    "plt.figure(figsize=(18, 8), dpi=1000)\n",
    "\n",
    "plt.errorbar(x1, avg_rest_uncertain, yerr=std_rest_uncertain, fmt='s', linestyle='--', capsize=5, label='Rest_uncertain_batch')\n",
    "plt.errorbar(x1, avg_rest_random, yerr=std_rest_random, fmt='s', ecolor='seagreen', linestyle='--', capsize=5, label='Rest_random_batch')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Ensure that the x-ticks correspond to the correct range and step\n",
    "plt.xticks(np.arange(1371, len(avg_rest_uncertain) * 3 + 1371, step=100))  # x-ticks every 15 units\n",
    "plt.xlabel('Train Data Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Test Accuracy Between Uncertainty Batch Sampling and Random Batch Sampling')\n",
    "plt.grid(True, linestyle='--')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
