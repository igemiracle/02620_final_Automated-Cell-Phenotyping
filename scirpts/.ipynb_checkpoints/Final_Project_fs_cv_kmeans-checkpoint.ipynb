{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba35bcc-4964-42f4-b4a2-58ea4d15ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d842ac-15dd-47f6-a5d3-bf265e614125",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c682d-d537-46c1-9f73-20672119039e",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "442d6c8c-9ff0-438b-a451-baff307b5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to perform feature engineering\n",
    "def data_preprocessing(data_df):\n",
    "    adata = ad.AnnData(X=data_df.values, \n",
    "                      obs=data_df.index.to_frame(), \n",
    "                      var=pd.DataFrame(index=data_df.columns))\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='cell_ranger')\n",
    "    adata_fselected = adata[:, adata.var['highly_variable']]\n",
    "    return adata_fselected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196468a9-ce37-456e-b8a2-1fac1ce36658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "\n",
    "## CellBench10x (5 lung cancer cell lines)\n",
    "lc_data_df = pd.read_csv('../data/10x_5cl/10x_5cl_data.csv', index_col=0)\n",
    "lc_label_df = pd.read_csv('../data/10x_5cl/Labels.csv',header=0) #the first row is header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "310598ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baron(Human) (Human pancreas)\n",
    "pan_data_df = pd.read_csv('../data/Baron Human/Filtered_Baron_HumanPancreas_data.csv', index_col=0)\n",
    "pan_label_df = pd.read_csv('../data/Baron Human/Labels.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41a6dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CD14+ Monocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CD14+ Monocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CD14+ Monocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CD14+ Monocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CD14+ Monocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>CD8+/CD45RA+ Naive Cytotoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>CD8+/CD45RA+ Naive Cytotoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>CD8+/CD45RA+ Naive Cytotoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>CD8+/CD45RA+ Naive Cytotoxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>CD8+/CD45RA+ Naive Cytotoxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  x\n",
       "0                    CD14+ Monocyte\n",
       "1                    CD14+ Monocyte\n",
       "2                    CD14+ Monocyte\n",
       "3                    CD14+ Monocyte\n",
       "4                    CD14+ Monocyte\n",
       "...                             ...\n",
       "19995  CD8+/CD45RA+ Naive Cytotoxic\n",
       "19996  CD8+/CD45RA+ Naive Cytotoxic\n",
       "19997  CD8+/CD45RA+ Naive Cytotoxic\n",
       "19998  CD8+/CD45RA+ Naive Cytotoxic\n",
       "19999  CD8+/CD45RA+ Naive Cytotoxic\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Zheng sorted\tPBMC (immune system)\n",
    "imm_data_df = pd.read_csv('../data/Zheng sorted/Filtered_DownSampled_SortedPBMC_data.csv', index_col=0)\n",
    "imm_label_df = pd.read_csv('../data/Zheng sorted/Labels.csv',header=0)\n",
    "imm_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ff1e32-917d-4723-978c-16c45cc3d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "lc_adata_fselected = data_preprocessing(lc_data_df)\n",
    "pan_adata_fselected = data_preprocessing(pan_data_df)\n",
    "imm_adata_fselected = data_preprocessing(imm_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8be56281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 3803 × 5000\n",
       "    obs: 0\n",
       "    var: 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'hvg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_adata_fselected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700b9b15",
   "metadata": {},
   "source": [
    "# cross vaildation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f80280c",
   "metadata": {},
   "source": [
    "#### After PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41330c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cv_datasets(features, labels, output_root):\n",
    "    \"\"\"\n",
    "    Create cross-validation datasets with an initial split into training and test datasets from CSV files,\n",
    "    saving features and labels in separate CSV files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split train and test (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    # Create Stratified K-Fold object\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Create directories and split data\n",
    "    for fold_index, (train_idx, valid_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        fold_dir = os.path.join(output_root, f'fold_{fold_index + 1}')\n",
    "        os.makedirs(fold_dir, exist_ok=True)\n",
    "        \n",
    "        # Select train and validation data\n",
    "        train_features = X_train.iloc[train_idx]\n",
    "        valid_features = X_train.iloc[valid_idx]\n",
    "        train_labels = y_train.iloc[train_idx].reset_index(drop=True)\n",
    "        valid_labels = y_train.iloc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "        # Save to CSV\n",
    "        train_features.to_csv(os.path.join(fold_dir, 'train_features.csv'), index=False)\n",
    "        valid_features.to_csv(os.path.join(fold_dir, 'valid_features.csv'), index=False)\n",
    "        train_labels.to_csv(os.path.join(fold_dir, 'train_labels.csv'), index=False)\n",
    "        valid_labels.to_csv(os.path.join(fold_dir, 'valid_labels.csv'), index=False)\n",
    "\n",
    "    # Save test set features and labels to separate CSV files\n",
    "    X_test.to_csv(os.path.join(output_root, 'test_features.csv'), index=False)\n",
    "    y_test.reset_index(drop=True).to_csv(os.path.join(output_root, 'test_labels.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1a5828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../clean_data_pca_cv\"\n",
    "\n",
    "# Load data from CSV\n",
    "lc_pca = pd.read_csv(\"../data_selected/lc_adata_fselected_31.csv\",index_col=0)\n",
    "imm_pca = pd.read_csv(\"../data_selected/imm_adata_fselected_107.csv\",index_col=0)\n",
    "pan_pca = pd.read_csv(\"../data_selected/pan_adata_fselected_8.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1611d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_cv_datasets(lc_pca,lc_label_df,output_dir+\"/cellBench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fb8ad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "create_cv_datasets(pan_pca,pan_label_df,output_dir+\"/baron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d193ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_cv_datasets(imm_pca,imm_label_df,output_dir+\"/zheng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c03ca",
   "metadata": {},
   "source": [
    "## No cv datasets\n",
    "### no cv, just split train and test data, for active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f39835a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(features, labels, output_root):\n",
    "\n",
    "    # Split train and test (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "   \n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    \n",
    "    # Save test set features and labels to separate CSV files\n",
    "    X_train.to_csv(os.path.join(output_root, 'train_features.csv'), index=False)\n",
    "    y_train.reset_index(drop=True).to_csv(os.path.join(output_root, 'train_labels.csv'), index=False)\n",
    "    X_test.to_csv(os.path.join(output_root, 'test_features.csv'), index=False)\n",
    "    y_test.reset_index(drop=True).to_csv(os.path.join(output_root, 'test_labels.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6c1b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../clean_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d044937",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets(lc_pca,lc_label_df,output_dir+\"/cellBench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad3179ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets(pan_pca,pan_label_df,output_dir+\"/baron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11f40278",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets(imm_pca,imm_label_df,output_dir+\"/zheng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495d433e-3d73-4641-a7eb-ec715f4610ae",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba907c-98e5-46f3-8c08-86ab031f40ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db75e1-1d0d-4406-9381-17dd0564bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to compute the Jaccard distances\n",
    "# It will receive 2 arrays for clusters results\n",
    "# and return the corresponding Jaccard distances between them\n",
    "def compute_Jaccard(clusters1, clusters2):\n",
    "    # Function to generate pairs using set\n",
    "    def generate_pairs(clusters):\n",
    "        pairs = set()\n",
    "        for i in range(len(clusters) - 1):\n",
    "            for j in range(i + 1, len(clusters)):\n",
    "                if clusters[i] == clusters[j]:\n",
    "                    pairs.add((i, j))  # Use tuple for immutable pair representation\n",
    "        return pairs\n",
    "\n",
    "    # Generate pairs for each clustering\n",
    "    pairs1 = generate_pairs(clusters1)\n",
    "    pairs2 = generate_pairs(clusters2)\n",
    "\n",
    "    # Compute intersections and unions\n",
    "    intersection = pairs1.intersection(pairs2)\n",
    "    union = pairs1.union(pairs2)\n",
    "\n",
    "    # Calculate Jaccard index\n",
    "    if not union:  # handle the case when both pairs are empty\n",
    "        return 1.0\n",
    "    Jaccard_dis = len(intersection) / len(union)\n",
    "    \n",
    "    return Jaccard_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2f5475-3687-4427-9467-2e0b6d8ed182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to perform the Kmeans clustering\n",
    "# It will return the objective values and the final clusters\n",
    "# It will stop after converging\n",
    "def perform_kmeans(mat, initial_center, k):\n",
    "    center = initial_center.copy()\n",
    "    obj = []\n",
    "    cluster = np.zeros((mat.shape[0],1))\n",
    "    check = True\n",
    "    count = 0\n",
    "    while check == True: # iteration loop\n",
    "        \n",
    "        obj_sum = 0\n",
    "        \n",
    "        for j in range(mat.shape[0]): # sample loop\n",
    "            dis = []\n",
    "            for c in range(k): # cluster loop\n",
    "                d = math.sqrt(sum((mat[j,:]-center[c,:])**2))\n",
    "                dis.append(d)\n",
    "            min_idx = dis.index(min(dis))\n",
    "            cluster[j, 0] = min_idx\n",
    "        \n",
    "        center = np.zeros((k, mat.shape[1]), float)\n",
    "        for j in range(mat.shape[0]): # sample loop\n",
    "            for c in range(k): # center loop\n",
    "                if cluster[j, 0] == c:\n",
    "                    center[c,:] += mat[j,:]\n",
    "        \n",
    "        for j in range(k): # center loop\n",
    "            if np.count_nonzero(cluster == j) != 0:\n",
    "                center[j, :] = center[j, :]/np.count_nonzero(cluster == j)\n",
    "        \n",
    "        for j in range(mat.shape[0]): # sample loop\n",
    "            for c in range(k): # center loop\n",
    "                if cluster[j,0] == c:\n",
    "                    obj_sum += sum((mat[j,:]-center[c,:])**2)\n",
    "        \n",
    "        obj.append(obj_sum)\n",
    "        \n",
    "        # check converge\n",
    "        if count != 0:\n",
    "            if obj[count] == obj[count-1]:\n",
    "                break\n",
    "                \n",
    "        count += 1\n",
    "        \n",
    "    return obj, cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca0a95a-8c28-452e-b291-a3b770af29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to initialize the centroids\n",
    "# it will return the centroids where each centroid's element is selected randomly \n",
    "# from the corresponding column of the original data \n",
    "def initialize_center(mat, k):\n",
    "    center = np.zeros((k, mat.shape[1]))\n",
    "    np.random.seed(620)\n",
    "    for c in range(k):\n",
    "        random_list = np.random.randint(0, mat.shape[0], size=mat.shape[0]).tolist()\n",
    "        for j in range(mat.shape[1]):\n",
    "            center[c,j] = mat[random_list[j],j]\n",
    "    return center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15880c43-82e9-4b81-b009-ff2d958836c0",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ecaeac-6dd6-44dc-9d08-ead0e0dbb7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data after PCA\n",
    "lc_pca = pd.read_csv('../data_selected/lc_adata_fselected_31.csv', index_col=0)\n",
    "pan_pca = pd.read_csv('../data_selected/pan_adata_fselected_8.csv', index_col=0)\n",
    "imm_pca = pd.read_csv('../data_selected/imm_adata_fselected_107.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c51b4c-fc90-4e42-8bf4-397414b1e79f",
   "metadata": {},
   "source": [
    "#### Perform Kmeans on three datastes after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc59e3e-5660-4040-a32f-95ce8e7eee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k(min_k, max_k, pca):\n",
    "    obj_list = []\n",
    "    for i in range(min_k, max_k+1):\n",
    "        obj, kmeans_cluster = perform_kmeans(np.array(pca), initialize_center(np.array(pca), i), i)\n",
    "        obj_list.append(obj[-1])\n",
    "        print('Kmeans k = '+str(i)+' finished!')\n",
    "\n",
    "    plt.plot([e for e in range(min_k, max_k+1)], obj_list, marker='o')\n",
    "    plt.title('Objective Function Values at Convergence over different k', fontsize=12)\n",
    "    plt.xlabel('k', fontsize=12)\n",
    "    plt.ylabel('Objective function', fontsize=12)\n",
    "    plt.xticks(range(min_k,max_k+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9c349d-f861-4fe4-be03-53c7c9262ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc select k\n",
    "select_k(1, 15, lc_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006eba9-ba54-4c70-aa8b-2019118015e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc kmeans\n",
    "lc_obj, lc_kmeans_cluster = perform_kmeans(np.array(lc_pca), initialize_center(np.array(lc_pca), 5), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c87ae-25fa-4310-b658-5edc23fae34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc get Jaccard index\n",
    "codes, uniques = pd.factorize(lc_label_df.iloc[:,0])\n",
    "lc_label_encode = np.array(pd.DataFrame({'Encoded': codes}))\n",
    "lc_label_arr = np.array([item[0] for item in lc_label_encode])\n",
    "lc_diff = compute_Jaccard(lc_label_arr, lc_kmeans_cluster)\n",
    "print('The Jaccard similarity between clustering result and original label of lung cancer cells is', lc_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec13184d-2809-46e7-81e8-93370088be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pan select k\n",
    "select_k(1, 20, pan_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b39c1-203e-4481-af33-092e67f8754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pan kmeans\n",
    "pan_obj, pan_kmeans_cluster = perform_kmeans(np.array(pan_pca), initialize_center(np.array(pan_pca), 14), 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7bf780-5f58-4a16-a3ed-9befbcca9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pan get Jaccard index\n",
    "codes, uniques = pd.factorize(pan_label_df.iloc[:,0])\n",
    "pan_label_encode = np.array(pd.DataFrame({'Encoded': codes}))\n",
    "pan_label_arr = np.array([item[0] for item in pan_label_encode])\n",
    "pan_diff = compute_Jaccard(pan_label_arr, pan_kmeans_cluster)\n",
    "print('The Jaccard similarity between clustering result and original label of pancreas cells is', pan_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04817c27-adad-47e0-9ec3-8683f8ed5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imm select k\n",
    "select_k(1, 15, imm_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d657f-51f7-4112-b405-0312b6c37d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imm kmeans\n",
    "imm_obj, imm_kmeans_cluster = perform_kmeans(np.array(imm_pca), initialize_center(np.array(imm_pca), 10), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0b864-ceb5-491b-992e-ca314c04467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imm get Jaccard index\n",
    "codes, uniques = pd.factorize(imm_label_df.iloc[:,0])\n",
    "imm_label_encode = np.array(pd.DataFrame({'Encoded': codes}))\n",
    "imm_label_arr = np.array([item[0] for item in imm_label_encode])\n",
    "imm_diff = compute_Jaccard(imm_label_arr, imm_kmeans_cluster)\n",
    "print('The Jaccard similarity between clustering result and original label of immune system cells is', imm_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2241c838-a73f-48c6-a060-75c543aa3f3b",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cefe71-545f-47fa-b48b-7e8e7ecf5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_name(label_num, label_df, label_arr):\n",
    "    labels = []\n",
    "    for i in range(label_num):\n",
    "        label_name = label_df.iloc[np.where(label_arr == i)[0][0], 0]\n",
    "        labels.append(label_name)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd7a55-5450-4352-a9a9-17c40ddd30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_cm(origin_cm):\n",
    "    cost_matrix = -origin_cm\n",
    "    \n",
    "    # Solve the assignment problem\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Reorder the confusion matrix\n",
    "    reordered_cm = origin_cm[row_ind, :]\n",
    "    reordered_cm = reordered_cm[:, col_ind]\n",
    "    \n",
    "    return reordered_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cbf2fa-8051-4f28-a472-7eb229c5c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_scores(cm):\n",
    "    # True Positives are the diagonal elements\n",
    "    TP = np.diag(cm)\n",
    "    # False Positives are the sum of the column minus the diagonal\n",
    "    FP = np.sum(cm, axis=0) - TP\n",
    "    # False Negatives are the sum of the row minus the diagonal\n",
    "    FN = np.sum(cm, axis=1) - TP\n",
    "    \n",
    "    # Precision for each class\n",
    "    precision = np.divide(TP, TP + FP, out=np.zeros_like(TP, dtype=float), where=(TP+FP)!=0)\n",
    "    # Recall for each class\n",
    "    recall = np.divide(TP, TP + FN, out=np.zeros_like(TP, dtype=float), where=(TP+FN)!=0)\n",
    "    \n",
    "    # F1 Score for each class\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)  # Adding a small epsilon to avoid division by zero\n",
    "\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f4a3b-d0ee-41d5-bdce-a58f4195c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_f1(cm):\n",
    "    f1_scores = compute_f1_scores(cm)\n",
    "    # Weighted-average F1 score\n",
    "    weights = np.sum(cm, axis=1) / np.sum(cm)  # Class weights based on support\n",
    "    weighted_f1 = np.average(f1_scores, weights=weights)\n",
    "    \n",
    "    return weighted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feaf4a9-303e-45af-b03a-76d3365a1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc kmeans visualization\n",
    "lc_labels = get_label_name(5, lc_label_df, lc_label_arr)\n",
    "lc_conf_matrix = confusion_matrix(lc_label_arr, lc_kmeans_cluster)\n",
    "lc_reordered_cm = reorder_cm(lc_conf_matrix)\n",
    "\n",
    "# plot the heatmap of reordered confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(lc_reordered_cm, annot=True, fmt=\"d\", cmap=\"Blues\", yticklabels=lc_labels)\n",
    "plt.title(\"Confusion Matrix with Jaccard Index of Lung Cancer Cell Lines: {:.2f}\".format(lc_diff), fontsize=14)\n",
    "plt.xlabel(\"Predicted clusters\", fontsize=12)\n",
    "plt.ylabel(\"True labels\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "lc_f1 = compute_weighted_f1(lc_reordered_cm)\n",
    "print('The weighted F1-score of Kmeans clustering on lung cancer cell lines is', lc_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2e8e8-4511-4f26-b91e-d10d2a3a1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pan kmeans visualization\n",
    "pan_labels = get_label_name(14, pan_label_df, pan_label_arr)\n",
    "pan_conf_matrix = confusion_matrix(pan_label_arr, pan_kmeans_cluster)\n",
    "pan_reordered_cm = reorder_cm(pan_conf_matrix)\n",
    "\n",
    "# plot the heatmap of reordered confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pan_reordered_cm, annot=True, fmt=\"d\", cmap=\"Blues\", yticklabels=pan_labels)\n",
    "plt.title(\"Confusion Matrix with Jaccard Index of Pancreas Cells: {:.2f}\".format(pan_diff), fontsize=14)\n",
    "plt.xlabel(\"Predicted clusters\", fontsize=12)\n",
    "plt.ylabel(\"True labels\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "pan_f1 = compute_weighted_f1(pan_reordered_cm)\n",
    "print('The weighted F1-score of Kmeans clustering on pancreas cells is', pan_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad9b9b-6e6c-4ad0-87d6-e15c50db671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imm kmeans visualization\n",
    "imm_labels = get_label_name(10, imm_label_df, imm_label_arr)\n",
    "imm_conf_matrix = confusion_matrix(imm_label_arr, imm_kmeans_cluster)\n",
    "imm_reordered_cm = reorder_cm(imm_conf_matrix)\n",
    "\n",
    "# plot the heatmap of reordered confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(imm_reordered_cm, annot=True, fmt=\"d\", cmap=\"Blues\", yticklabels=imm_labels)\n",
    "plt.title(\"Confusion Matrix with Jaccard Index of Immune System Cells: {:.2f}\".format(imm_diff), fontsize=14)\n",
    "plt.xlabel(\"Predicted clusters\", fontsize=12)\n",
    "plt.ylabel(\"True labels\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "imm_f1 = compute_weighted_f1(imm_reordered_cm)\n",
    "print('The weighted F1-score of Kmeans clustering on immune system cells is', imm_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42cb0d-c0f4-49ac-b5ec-c20a9de3bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the Jaccard Index and F1-score of Kmeans\n",
    "\n",
    "jacc_F1 = {\n",
    "    'Dataset': ['Baron', 'Baron', 'CellBench', 'CellBench', 'Zheng', 'Zheng'],\n",
    "    'Metric': ['Jaccard Index', 'F1-score', 'Jaccard Index', 'F1-score', 'Jaccard Index', 'F1-score'],\n",
    "    'values': [0.23, 0.495124148777054, 0.34, 0.6346396368152479, 0.18, 0.3181956174307169]\n",
    "}\n",
    "\n",
    "jacc_F1_df = pd.DataFrame(jacc_F1)\n",
    "\n",
    "# Pivot the data for plotting\n",
    "df_pivot = jacc_F1_df.pivot(index='Dataset', columns='Metric', values='values')\n",
    "\n",
    "# Plot\n",
    "ax = df_pivot.plot(kind='bar', figsize=(8, 6), width=0.4)\n",
    "plt.title('Evaluation for Kmeans on Three Datasets', fontsize=14)\n",
    "plt.ylabel('Metric Values', fontsize=12)\n",
    "plt.xlabel('Datasets', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Metric types', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649c067",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c26a56",
   "metadata": {},
   "source": [
    "### To run the logistic regression model on cross validation dataset, JUST run these cmd:\n",
    "#### bash run_lr_cv.sh baron\n",
    "#### bash run_lr_cv.sh cellBench\n",
    "#### bash run_lr_cv.sh zheng\n",
    "### The bash script will automatically call the lr_final.py, then generate the metric.txt for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c039a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics for the 10 fold\n",
    "\n",
    "def calculate_average_metrics(directory):\n",
    "    # Initilize DataFrame\n",
    "    total_train_error = 0.0\n",
    "    total_test_error = 0.0\n",
    "    total_f1_score = 0.0\n",
    "    file_count = 0\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                if len(lines) == 3:\n",
    "                    total_train_error += float(lines[0].split(',')[1])\n",
    "                    total_test_error += float(lines[1].split(',')[1])\n",
    "                    total_f1_score += float(lines[2].split(',')[1])\n",
    "                    file_count += 1\n",
    "\n",
    "    if file_count > 0:\n",
    "        avg_train_error = total_train_error / file_count\n",
    "        avg_test_error = total_test_error / file_count\n",
    "        avg_f1_score = total_f1_score / file_count\n",
    "    else:\n",
    "        avg_train_error, avg_test_error, avg_f1_score = 0, 0, 0\n",
    "\n",
    "    return avg_train_error, avg_test_error, avg_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bf540e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../clean_data_pca/baron/metrics'\n",
    "\n",
    "baron_averages = calculate_average_metrics(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "278ce407",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../clean_data_pca/cellBench/metrics'\n",
    "\n",
    "cell_averages = calculate_average_metrics(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47ca8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../clean_data_pca/zheng/metrics'\n",
    "\n",
    "zheng_averages = calculate_average_metrics(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb6e8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(output,averages):\n",
    "    with open(output, 'w') as file:\n",
    "        file.write(\"Metric,Value\\n\")\n",
    "        file.write(f\"Train Error,{averages[0]}\\n\")\n",
    "        file.write(f\"Test Error,{averages[1]}\\n\")\n",
    "        file.write(f\"F1 Score,{averages[2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e83e0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(\"../LR_results/baron_avg_metrics.csv\",baron_averages)\n",
    "write_csv(\"../LR_results/cell_avg_metrics.csv\",cell_averages)\n",
    "write_csv(\"../LR_results/zheng_avg_metrics.csv\",zheng_averages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
